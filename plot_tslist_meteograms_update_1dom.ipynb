{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19dd65e-44a5-4f18-b94b-791b7765e094",
   "metadata": {},
   "source": [
    "# \n",
    "Plot Time Series w/ Observations (To get siphcat to get the text files -- USE THIS ONE!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f447c1-d96c-4e5f-a31e-e4c6fe161096",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9073fcc9-de66-43ad-b97e-b138bb803ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Libraries\n",
    "#\n",
    "\n",
    "import numpy             as np\n",
    "import datetime          as datetime\n",
    "import os                as os\n",
    "import platform          as platform\n",
    "import xarray            as xr\n",
    "import pandas            as pd\n",
    "import glob              as glob\n",
    "import siphon.catalog    as siphcat  \n",
    "import siphon.ncss       as siphncss\n",
    "import seaborn           as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pint_xarray       as px\n",
    "import pint              as pint\n",
    "import matplotlib.dates  as mdates\n",
    "import timezonefinder    as tzf\n",
    "import pytz              as pytz\n",
    "import haversine         as hs\n",
    "import socket            as socket\n",
    "import metpy.calc        as mpcalc\n",
    "import metpy.units       as mpunits\n",
    "import pathlib           as pathlib\n",
    "\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "import metpy.io          as mpio\n",
    "\n",
    "\n",
    "from requests import HTTPError\n",
    "from datetime import timezone\n",
    "\n",
    "\n",
    "from metpy.units import units\n",
    "\n",
    "import airportsdata as airpt\n",
    "\n",
    "ureg = pint.UnitRegistry()\n",
    "Q_ = ureg.Quantity\n",
    "\n",
    "\n",
    "def haversine(row):\n",
    "    lon1 = station_lon\n",
    "    lat1 = station_lat\n",
    "    lon2 = row['longitude']\n",
    "    lat2 = row['latitude']\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    km = 6367 * c\n",
    "    return km\n",
    "    \n",
    "    \n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29e546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Mines Colors and Fonts\n",
    "#\n",
    "\n",
    "Mines_Blue = \"#002554\"\n",
    "\n",
    "\n",
    "plt.rcParams.update({'text.color'      : Mines_Blue,\n",
    "                     'axes.labelcolor' : Mines_Blue,\n",
    "\t\t\t\t\t 'axes.edgecolor'  :Mines_Blue,\n",
    "\t\t\t\t\t 'xtick.color'     : Mines_Blue,\n",
    "\t\t\t\t\t 'ytick.color'    : Mines_Blue})\n",
    "\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54abbc2b-358d-4c0e-a1eb-0752574563f6",
   "metadata": {},
   "source": [
    "## File Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c1513b9-a791-41cb-a4c6-67ba8ca945ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory is now /Users/wjc/GitHub/SD_Mines_WRF_REALTIME\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# File Organization\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "beta_on     = 0\n",
    "max_domains = 1\n",
    "\n",
    "if (socket.gethostname() == \"kyrill\"):\n",
    "    WRF_OVERALL_DIR = \"/projects/SD_Mines_WRF_REALTIME/\"\n",
    "else:\n",
    "    if (platform.system() == \"Darwin\"):\n",
    "         WRF_OVERALL_DIR = \"/Users/wjc/GitHub/SD_Mines_WRF_REALTIME/\"\n",
    "    else:\n",
    "         WRF_OVERALL_DIR = \"/home/wjc/GitHub/SD_Mines_WRF_REALTIME/\"\n",
    "\n",
    "\n",
    "os.chdir(WRF_OVERALL_DIR)\n",
    "\n",
    "print( \"Current Working Directory is now \" + os.getcwd() )\n",
    "    \n",
    "WPS_WORK    = WRF_OVERALL_DIR + \"./WPS_PrepArea/\"\n",
    "WPS_EXE     = WRF_OVERALL_DIR + \"./WRF4/WPS/\"\n",
    "WRF_EXE     = WRF_OVERALL_DIR + \"./WRF4/WRF/test/em_real/\"\n",
    "WRF_ARCHIVE = WRF_OVERALL_DIR + \"./ARCHIVE/\"\n",
    "WRF_IMAGES  = WRF_OVERALL_DIR + \"./WEB_IMAGES/\"\n",
    "METAR_DIR   = WRF_OVERALL_DIR + \"./METARS/\"\n",
    "\n",
    "\n",
    "\n",
    "station_list_file = WRF_OVERALL_DIR + \"namelist_files_and_local_scripts/time_series_station_files_\"+str(max_domains)+\"_dom_all.xlsx\"\n",
    "\n",
    "os.chdir(WRF_EXE)\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6054cd4-e5eb-47a1-b1b2-b92d7d7c723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Model Geographic Limits\n",
    "#\n",
    "\n",
    "f_geog = xr.open_dataset(filename_or_obj= WRF_ARCHIVE + \"/GEOGRID_EM_FILES/geo_em.d01.nc\")\n",
    "\n",
    "lat2d_d01 = f_geog[ \"XLAT_C\"]\n",
    "lon2d_d01 = f_geog[\"XLONG_C\"]\n",
    "\n",
    "geospatial_lat_min =  lat2d_d01.values.min()\n",
    "geospatial_lat_max =  lat2d_d01.values.max()\n",
    "geospatial_lon_min =  lon2d_d01.values.min()\n",
    "geospatial_lon_max =  lon2d_d01.values.max()\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916739ca-6473-4a28-a2c8-a37fd62271d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92a53e41-be5b-4d89-b19f-5fb97bc31de9",
   "metadata": {},
   "source": [
    "## Time Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d853823c-6405-4651-ae87-1c34da5c3db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-10_00:00:00\n",
      "Model Simulation Date  2024-10-10 00:00:00+00:00\n",
      "         Model Start Datetime is  2024-10-10 00:00:00+00:00\n",
      "           Model End Datetime is  2024-10-11 12:00:00+00:00\n",
      "             Current Datetime is  2024-11-29 04:57:19.199349+00:00\n",
      "          Siphon End Datetime is  2024-10-11 12:00:00+00:00\n",
      "Index(['20241010_0000', '20241010_0100', '20241010_0200', '20241010_0300',\n",
      "       '20241010_0400', '20241010_0500', '20241010_0600', '20241010_0700',\n",
      "       '20241010_0800', '20241010_0900', '20241010_1000', '20241010_1100',\n",
      "       '20241010_1200', '20241010_1300', '20241010_1400', '20241010_1500',\n",
      "       '20241010_1600', '20241010_1700', '20241010_1800', '20241010_1900',\n",
      "       '20241010_2000', '20241010_2100', '20241010_2200', '20241010_2300',\n",
      "       '20241011_0000', '20241011_0100', '20241011_0200', '20241011_0300',\n",
      "       '20241011_0400', '20241011_0500', '20241011_0600', '20241011_0700',\n",
      "       '20241011_0800', '20241011_0900', '20241011_1000', '20241011_1100',\n",
      "       '20241011_1200'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open(WRF_ARCHIVE  + \"./current_complete_run/current_run.txt\") as f:\n",
    "    model_start_date_YYYY_MM_DD_HH = f.readlines()\n",
    "\n",
    "model_start_date_YYYY_MM_DD_HH     = model_start_date_YYYY_MM_DD_HH[0][0:13]\n",
    "\n",
    "model_start_date_YYYY_MM_DD_HH0000 = model_start_date_YYYY_MM_DD_HH + \":00:00\"\n",
    "print(model_start_date_YYYY_MM_DD_HH0000)\n",
    "    \n",
    "model_start_datetime = pd.to_datetime(datetime.datetime.strptime(model_start_date_YYYY_MM_DD_HH0000, '%Y-%m-%d_%H:%M:%S')).tz_localize(tz=\"UTC\")\n",
    "print(\"Model Simulation Date \", model_start_datetime)\n",
    "    \n",
    "model_end_datetime   = model_start_datetime + datetime.timedelta(hours=36)\n",
    "current_datetime     = datetime.datetime.now(tz=timezone.utc)\n",
    "siphon_end_datetime  = min(current_datetime, model_end_datetime)\n",
    "\n",
    "print(\"         Model Start Datetime is \", model_start_datetime)\n",
    "print(\"           Model End Datetime is \",   model_end_datetime)\n",
    "print(\"             Current Datetime is \",     current_datetime)\n",
    "print(\"          Siphon End Datetime is \",  siphon_end_datetime)\n",
    "\n",
    "\n",
    "siphon_time_series       = pd.date_range(model_start_datetime, siphon_end_datetime,freq='h')\n",
    "siphon_pulls_YYYYMMDD_HH = siphon_time_series.strftime(\"%Y%m%d_%H00\")\n",
    "\n",
    "print(siphon_pulls_YYYYMMDD_HH)\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f1f13-21b4-4ee1-ae4c-7e551914c5a1",
   "metadata": {},
   "source": [
    "## Read tslist excel file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f61d9f40-9106-41b1-b8a7-727e33172e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file from /Users/wjc/GitHub/SD_Mines_WRF_REALTIME/namelist_files_and_local_scripts/time_series_station_files_1_dom_all.xlsx\n",
      "          Station ID  Domain               Station Name  Latitude  Longitude  \\\n",
      "Row Label                                                                      \n",
      "41              KUNR       1         Rapid City NWS, SD   44.0727  -103.2110   \n",
      "34              KRCA       1          Ellsworth AFB, SD   44.1330  -103.1000   \n",
      "33              KRAP       1     Rapid City Airport, SD   44.0430  -103.0540   \n",
      "40              KUDX       1     Rapid City, NEXRAD, SD   44.1330  -102.8330   \n",
      "11              KCUT       1         Custer Airport, SD   43.7330  -103.6110   \n",
      "37              KSPF       1        Clyde Ice Field, SD   44.4830  -103.7830   \n",
      "16              KEFC       1  Belle Fourche Airport, SD   44.7340  -103.8620   \n",
      "43              KW43       1         Hulett Airport, WY   44.6629  -104.5680   \n",
      "31              KPHP       1         Philip Airport, SD   44.0510  -101.6010   \n",
      "26              KIEN       1     Pine Ridge Airport, SD   43.0210  -102.5180   \n",
      "10              KCDR       1        Chadron Airport, NE   42.8370  -103.0980   \n",
      "2               K4MC       1              Moorcroft, WY   44.2670  -104.9500   \n",
      "13              KD07       1          Faith Airport, SD   45.0320  -102.0190   \n",
      "24              KGRN       1         Gordon Airport, NE   42.8060  -102.1750   \n",
      "0               K2WX       1                Buffalo, SD   45.6040  -103.5460   \n",
      "19              KGCC       1      Gillette  Airport, WY   44.3390  -105.5420   \n",
      "25              KHEI       1      Hettinger Airport, ND   46.0140  -102.6550   \n",
      "44              KY22       1                 Lemmon, SD   45.9330  -102.1670   \n",
      "28              KLEM       1         Lemmon Airport, SD   45.9190  -102.1060   \n",
      "15              KDGW       1   Converse, CO Airport, WY   42.7960  -105.3800   \n",
      "4               KAIA       1       Alliance Airport, NE   42.0500  -102.8000   \n",
      "1               K4DG       1                Douglas, WY   42.7500  -105.3830   \n",
      "8               KBWW       1         Bowman Airport, ND   46.1655  -103.3000   \n",
      "36              KSIB       1            Sibley Peak, WY   42.4330  -105.0330   \n",
      "32              KPIR       1         Pierre Airport, SD   44.3810  -100.2860   \n",
      "39              KTOR       1     Torrington Airport, WY   42.0610  -104.1580   \n",
      "29              KMIS       1                Mission, SD   43.0330  -100.6170   \n",
      "5               KBFF       1    Scottsbluff Airport, NE   41.8710  -103.5930   \n",
      "42              KVTN       1   Miller Field Airport, NE   42.8780  -100.5500   \n",
      "12              KCYS       1           Cheyenne NWS, WY   41.1556  -104.8100   \n",
      "6               KBIS       1            Bismark NWS, ND   46.7727  -100.7460   \n",
      "27              KLBF       1       North Platte NWS, NE   41.1262  -100.6840   \n",
      "3               KABR       1           Aberdeen NWS, SD   45.4467   -98.4224   \n",
      "35              KRIW       1           Riverton NWS, WY   43.0642  -108.4600   \n",
      "9               KBYZ       1           Billings NWS, MT   45.7502  -108.5700   \n",
      "14              KDEN       1    Denver Intl Airport, CO   39.8617  -104.6730   \n",
      "7               KBOU       1            Boulder NWS, CO   39.9920  -105.2610   \n",
      "18              KFSD       1        Sioux Falls NWS, SD   43.5820   -96.7419   \n",
      "20              KGGW       1            Glasgow NWS, MT   48.2124  -106.6150   \n",
      "23              KGLD       1           Goodland NWS, KS   39.3707  -101.6990   \n",
      "21              KGID       1           Hastings NWS, NE   40.6475   -98.3837   \n",
      "45              MUNS       1          Munich School, ND   48.6675   -98.8344   \n",
      "17              KFGF       1        Grand Forks NWS, ND   47.9219   -97.0981   \n",
      "30              KOAX       1       Omaha-Valley NWS, NE   41.3197   -96.3670   \n",
      "22              KGJT       1     Grand Junction NWS, CO   39.1224  -108.5270   \n",
      "38              KTOP       1             Topeka NWS, KS   39.0688   -95.6224   \n",
      "\n",
      "           Distane from SDMines  \n",
      "Row Label                        \n",
      "41                     0.431106  \n",
      "34                    10.682914  \n",
      "33                    12.697569  \n",
      "40                    30.519657  \n",
      "11                    49.952993  \n",
      "37                    64.535897  \n",
      "16                    89.899071  \n",
      "43                   126.431824  \n",
      "31                   128.314056  \n",
      "26                   129.664385  \n",
      "10                   137.928701  \n",
      "2                    140.677352  \n",
      "13                   142.055253  \n",
      "24                   163.841093  \n",
      "0                    172.119642  \n",
      "19                   188.446333  \n",
      "25                   219.926642  \n",
      "44                   222.183305  \n",
      "28                   222.560325  \n",
      "15                   225.863551  \n",
      "4                    227.569443  \n",
      "1                    229.354496  \n",
      "8                    232.578270  \n",
      "36                   234.958321  \n",
      "32                   235.171039  \n",
      "39                   236.894539  \n",
      "29                   238.669648  \n",
      "5                    247.072064  \n",
      "42                   252.293974  \n",
      "12                   350.108606  \n",
      "6                    356.136514  \n",
      "27                   387.428774  \n",
      "3                    407.283582  \n",
      "35                   437.822358  \n",
      "9                    461.483986  \n",
      "14                   483.897878  \n",
      "7                    484.626545  \n",
      "18                   521.333825  \n",
      "20                   529.602582  \n",
      "23                   537.812992  \n",
      "21                   549.604300  \n",
      "45                   610.755486  \n",
      "17                   636.523335  \n",
      "30                   637.100226  \n",
      "22                   706.059707  \n",
      "38                   840.717031  \n",
      "['KUNR', 'KRCA', 'KRAP', 'KUDX', 'KCUT', 'KSPF', 'KEFC', 'KW43', 'KPHP', 'KIEN', 'KCDR', 'K4MC', 'KD07', 'KGRN', 'K2WX', 'KGCC', 'KHEI', 'KY22', 'KLEM', 'KDGW', 'KAIA', 'K4DG', 'KBWW', 'KSIB', 'KPIR', 'KTOR', 'KMIS', 'KBFF', 'KVTN', 'KCYS', 'KBIS', 'KLBF', 'KABR', 'KRIW', 'KBYZ', 'KDEN', 'KBOU', 'KFSD', 'KGGW', 'KGLD', 'KGID', 'MUNS', 'KFGF', 'KOAX', 'KGJT', 'KTOP']\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Read TSLIST Excel File\n",
    "#\n",
    "\n",
    "print(\"read file from \"+station_list_file)\n",
    "\n",
    "available_time_series_list = pd.read_excel(station_list_file,\n",
    "                                           index_col=0)\n",
    "\n",
    "print(available_time_series_list)\n",
    "\n",
    "target_time_series_as_list = available_time_series_list[\"Station ID\"].to_list()\n",
    "print(target_time_series_as_list)\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1fc178",
   "metadata": {},
   "source": [
    "## Get Station Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0274cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Airport Data\n",
    "#\n",
    "\n",
    "airport_database = airpt.load('ICAO')\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62308d5",
   "metadata": {},
   "source": [
    "## Pull METARS from Siphon Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec290040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box =  38.169743 50.48948\n",
      "       -112.13367 -93.36633\n",
      "/Users/wjc/GitHub/SD_Mines_WRF_REALTIME/METARS/metar_20241010_0000.txt False\n",
      "downloading https://thredds-dev.unidata.ucar.edu/thredds/fileServer/noaaport/text/metar/metar_20241010_0000.txt\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: 404",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Pull File \u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m metar_url)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetar_url\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response, \u001b[38;5;28mopen\u001b[39m(metar_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out_file:\n\u001b[1;32m     32\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(response, out_file)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcracking \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mmetar_file)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/urllib/request.py:215\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/urllib/request.py:521\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    520\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 521\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/urllib/request.py:630\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 630\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/urllib/request.py:559\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    558\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/urllib/request.py:492\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    491\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 492\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/urllib/request.py:639\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 639\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: 404"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Pull METARS from UNIDATA NOAAPORT Experimental Site\n",
    "#\n",
    "# https://thredds-test.unidata.ucar.edu/thredds/fileServer/noaaport/text/metar/metar_20210924_0000.txt\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "print(\"Box = \",geospatial_lat_min, geospatial_lat_max)\n",
    "print(\"      \",geospatial_lon_min, geospatial_lon_max)\n",
    "\n",
    "\n",
    "first = True\n",
    "for datehour in siphon_pulls_YYYYMMDD_HH:\n",
    "\n",
    "    # URLs & Local Work File Names\n",
    "    \n",
    "    metar_url  = \"https://thredds-dev.unidata.ucar.edu/thredds/fileServer/noaaport/text/metar/metar_\"+datehour+\".txt\"\n",
    "    metar_file = METAR_DIR + \"./metar_\"+datehour+\".txt\"\n",
    "    \n",
    "    path_to_file = pathlib.Path(metar_file)\n",
    "    \n",
    "    print(path_to_file, path_to_file.is_file())\n",
    "\n",
    "    # Pull File \n",
    "    \n",
    "    print(\"downloading \"+ metar_url)\n",
    "    with urllib.request.urlopen(metar_url) as response, open(metar_file, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)\n",
    "            \n",
    "    print(\"cracking \"+metar_file)\n",
    "    try:\n",
    "        indata = mpio.metar.parse_metar_file(metar_file)\n",
    "        indata = indata[(indata['latitude']  > geospatial_lat_min) & \n",
    "                        (indata['latitude']  < geospatial_lat_max) &\n",
    "                        (indata['longitude'] > geospatial_lon_min) &\n",
    "                        (indata['longitude'] < geospatial_lon_max) ]\n",
    "        indata = indata.drop([\"current_wx2_symbol\",\n",
    "                              \"current_wx3_symbol\",\n",
    "                              \"current_wx1\",\n",
    "                              \"current_wx2\",\n",
    "                              \"current_wx3\",\n",
    "                              \"altimeter\",\n",
    "                              \"wind_gust\",\n",
    "                              \"visibility\",\n",
    "                              \"cloud_coverage\",\n",
    "                              \"current_wx1_symbol\",\n",
    "                              \"air_pressure_at_sea_level\",\n",
    "                              \"remarks\",\n",
    "                              \"low_cloud_type\", \n",
    "                              \"low_cloud_level\", \n",
    "                              \"medium_cloud_type\",\n",
    "                              \"medium_cloud_level\", \n",
    "                              \"high_cloud_type\", \n",
    "                              \"high_cloud_level\",\n",
    "                              \"highest_cloud_type\", \n",
    "                              \"highest_cloud_level\"], axis=1)\n",
    "        if first:\n",
    "            first = False\n",
    "            metar_dataframe = indata\n",
    "        else:\n",
    "            metar_dataframe = pd.concat(objs = [metar_dataframe,indata],\n",
    "                                        axis =                  \"index\")\n",
    "    except ValueError:\n",
    "        print(\"BALLS! Parse Error\")\n",
    "        error_404 = True\n",
    "        pass\n",
    "\n",
    "# Cookiecut the Radar Domain Metars and Clean Data Table\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metar_dataframe = metar_dataframe.sort_values(\"date_time\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(    \"purging \" + METAR_DIR + \"./metar_*.txt\")\n",
    "os.system(\"rm -frv \" + METAR_DIR + \"./metar_*.txt\")\n",
    "\n",
    "print(\"Dropping Duplicate Records\")\n",
    "\n",
    "metar_dataframe = metar_dataframe.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    metar_station_locs = metar_dataframe[[\"station_id\",\"latitude\",\"longitude\"]].drop_duplicates()\n",
    "except:\n",
    "    print(\"Dangit: there is no metar stations to locate\")\n",
    "\n",
    "print(\"Storing Data in CSVs\")\n",
    "metar_station_locs.to_csv(WRF_OVERALL_DIR + \"Metar_loc_dump.csv\")\n",
    "metar_dataframe.to_csv(   WRF_OVERALL_DIR + \"Metar_Dump.csv\")\n",
    "print(\"Metar Extraction Complete\")\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a899ce-0e6d-472c-bd3a-d40ecf3302bb",
   "metadata": {},
   "source": [
    "## Rotate through Available Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647bb3fa-f35e-4c77-90c8-53253f5499a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Rotate through Available Files\n",
    "#\n",
    "\n",
    "file_time = model_start_datetime.strftime('%Y-%m-%d_%H')\n",
    "\n",
    "TS_DIR    = WRF_ARCHIVE  + \"./current_complete_run/STATION_TIME_SERIES/\"\n",
    "\n",
    "#\n",
    "# Creating Graphics Directory\n",
    "#\n",
    "\n",
    "graphics_directory = WRF_IMAGES + \"./current_complete_run/STATION_TIME_SERIES/\"\n",
    "\n",
    "print(\"Creating \" + graphics_directory)\n",
    "\n",
    "os.system(\"mkdir -pv \" + graphics_directory )\n",
    "\n",
    "#\n",
    "# Start File Rotation\n",
    "#\n",
    "\n",
    "\n",
    "for station_row in range(len(available_time_series_list)):\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Pull Station Data \n",
    "    #\n",
    "\n",
    "\n",
    "\n",
    "    station_id     = available_time_series_list.iloc[station_row][\"Station ID\"]\n",
    "    grid_domain    = available_time_series_list.iloc[station_row][\"Domain\"]\n",
    "    station_name   = available_time_series_list.iloc[station_row][\"Station Name\"]\n",
    "    station_lat    = available_time_series_list.iloc[station_row][\"Latitude\"]\n",
    "    station_lon    = available_time_series_list.iloc[station_row][\"Longitude\"]\n",
    "\n",
    "\n",
    "    #    \n",
    "    ###################################################################\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Pull WRF Time Series\n",
    "    #\n",
    "    \n",
    "    netcdf_file_name = TS_DIR + \"./wrfout_d\"+str(grid_domain).zfill(2)+\"_\"+file_time+\"_\"+station_id+\".nc\"\n",
    "    \n",
    "    wrf_timeseries = xr.open_dataset(netcdf_file_name, \n",
    "                                     engine='netcdf4')\n",
    "    \n",
    "    print(netcdf_file_name)\n",
    "\n",
    "    #\n",
    "    ###################################################################\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Select Metars for Closest Station\n",
    "    #\n",
    "\n",
    "  \n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Get METARS for Station \n",
    "    #\n",
    "    \n",
    "\n",
    "\n",
    "    #\n",
    "    # Get Nearest Station to Requested Station Point\n",
    "    #\n",
    "    \n",
    "    metar_station_locs['distance'] = metar_station_locs.apply(lambda row: haversine(row), axis=1)\n",
    "    \n",
    "    x=metar_station_locs[ metar_station_locs['distance'] == metar_station_locs['distance'].min() ]\n",
    "    \n",
    "    try:\n",
    "        weather_station_name = airport_database[x.iloc[0]['station_id']][\"name\"] #+\", \"+airport_database[x['station_id'][0]][\"subd\"]\n",
    "        print(\"Weatherstation from airport database \", weather_station_name)\n",
    "    except KeyError:\n",
    "        weather_station_name = x.iloc[0]['station_id']\n",
    "        print(\"Weatherstation from short table \", weather_station_name)\n",
    "\n",
    "               \n",
    "    metar_data = metar_dataframe[metar_dataframe[\"station_id\"]==x.iloc[0]['station_id']].set_index(\"date_time\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"lon metar/station/wrf:\",metar_data.iloc[0][\"longitude\"],station_lon,wrf_timeseries[\"wrf_grid_longitude\"].values)\n",
    "    print(\"lat metar/station/wrf:\",metar_data.iloc[0][ \"latitude\"],station_lat,wrf_timeseries[\"wrf_grid_latitude\"].values)\n",
    "\n",
    "   \n",
    "\n",
    "    metar_to_sta_distance  = hs.haversine((metar_data.iloc[0][ \"latitude\"],\n",
    "                                           metar_data.iloc[0][\"longitude\"]),\n",
    "                                          (station_lat,\n",
    "                                           station_lon))\n",
    "\n",
    "    metar_to_wrf_distance = hs.haversine((metar_data.iloc[0][ \"latitude\"],\n",
    "                                          metar_data.iloc[0][\"longitude\"]),\n",
    "                                          (wrf_timeseries[\"wrf_grid_latitude\" ].values[0],\n",
    "                                           wrf_timeseries[\"wrf_grid_longitude\"].values[0]))\n",
    "\n",
    "\n",
    "    sta_to_wrf_distance   = hs.haversine((station_lat,\n",
    "                                          station_lon),\n",
    "                                         (wrf_timeseries[\"wrf_grid_latitude\" ].values[0],\n",
    "                                          wrf_timeseries[\"wrf_grid_longitude\"].values[0]))    \n",
    "    \n",
    "    print(\"distance between  metar and tslist \",metar_to_sta_distance)\n",
    "    print(\"distance between  metar and    wrf \",metar_to_wrf_distance)\n",
    "    print(\"distance between tslist and    wrf \",sta_to_wrf_distance)\n",
    "\n",
    "    \n",
    "    \n",
    "    #    \n",
    "    ###################################################################    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    ###################################################################    \n",
    "    \n",
    "\n",
    "    ###################################################################\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Create Meteogram\n",
    "    #\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Time Axes\n",
    "    #\n",
    "                                         \n",
    "    tf     = tzf.TimezoneFinder()\n",
    "    tz     = tf.certain_timezone_at(lng=station_lon, lat=station_lat)\n",
    "    \n",
    "    tzabbr = pytz.timezone(tz)#.localize(model_start_datetime)\n",
    "\n",
    "    wrf_times  = pd.to_datetime(wrf_timeseries[\"time\"]).tz_localize(tz=\"UTC\").tz_convert(tz=tz)\n",
    "    \n",
    "    ncss_times = pd.to_datetime(metar_data.index).tz_localize(tz=\"UTC\").tz_convert(tz=tz)\n",
    "\n",
    "\n",
    "\n",
    "    wrf_time_seconds  =  wrf_times.minute*60+wrf_times.second \n",
    "    on_the_hour       = np.where(wrf_time_seconds ==0)\n",
    "    wrf_time_hrly     = wrf_times[on_the_hour]\n",
    "    wrf_time_hrly_bar = wrf_times[on_the_hour]-datetime.timedelta(minutes=30)\n",
    "\n",
    "    #\n",
    "    ###################################################################\n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Precip Prep\n",
    "    #\n",
    "\n",
    "    wrf_cum_prec      = wrf_timeseries[\"stratiform_precipitation_amount\"].values + wrf_timeseries[\"convective_precipitation_amount\"].values\n",
    "    print(\"Total precip: \",np.sum(wrf_cum_prec)/25.4, \" in\")\n",
    "    if (np.sum(wrf_cum_prec)/25.4 < 0.005):\n",
    "        print(\"No Significant Rainfall\")\n",
    "        wrf_cum_prec[:] = 0.000\n",
    "    \n",
    "    wrf_cum_hrly_prec = wrf_cum_prec[on_the_hour]\n",
    "    wrf_hrly_prec     = wrf_cum_hrly_prec.copy()\n",
    "\n",
    "    wrf_hrly_prec[1:] = wrf_cum_hrly_prec[1:] - wrf_cum_hrly_prec[0:-1]\n",
    "    \n",
    "    wrf_hrly_prec     = wrf_hrly_prec     / 25.4\n",
    "    wrf_cum_hrly_prec = wrf_cum_hrly_prec / 25.4\n",
    "    wrf_cum_prec      = wrf_cum_prec      / 25.4\n",
    "\n",
    "    #\n",
    "    ###################################################################\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Wind Barb Prep\n",
    "    #\n",
    "\n",
    "    u_wrf = (wrf_timeseries[\"eastward_wind_10m\"]*units(\"m\")/units(\"s\")).pint.to(\"knots\")[on_the_hour]\n",
    "    v_wrf = (wrf_timeseries[\"northward_wind_10m\"]*units(\"m\")/units(\"s\")).pint.to(\"knots\")[on_the_hour]\n",
    "\n",
    "    spd_wrf = np.sqrt(wrf_timeseries[ \"eastward_wind_10m\"]**2 + \n",
    "                      wrf_timeseries[\"northward_wind_10m\"]**2 )\n",
    "    \n",
    "    \n",
    "    spd_wrf = (spd_wrf *units(\"m\")/units(\"s\")).pint.to(\"knots\")                 \n",
    "\n",
    "    obs_winddir   =  metar_data[\"wind_direction\"].to_numpy() * units(\"deg\")\n",
    "    obs_windspeed = (metar_data[\"wind_speed\"].to_numpy() * units(\"m\")/units(\"s\")).to(\"knots\") \n",
    "\n",
    "\n",
    "\n",
    "    u_obs = (metar_data[ \"eastward_wind\"].to_numpy() * units(\"m\")/units(\"s\")).to(\"knots\") \n",
    "    v_obs = (metar_data[\"northward_wind\"].to_numpy() * units(\"m\")/units(\"s\")).to(\"knots\") \n",
    "\n",
    "    #u_obs = xr.DataArray(data=u_obs)#, coords={\"time\":ncss_times})\n",
    "    #v_obs = xr.DataArray(data=v_obs)#, coords={\"time\":ncss_times})\n",
    "    #\n",
    "    ###################################################################\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Plot Meteogram\n",
    "    #\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12, 8),\n",
    "                           nrows   =  2, \n",
    "                           ncols   =  2,\n",
    "                           sharex  =  True)\n",
    "\n",
    "    date_form = mdates.DateFormatter(\"%H %Z\\n%d %b\", tz=pytz.timezone(tz))\n",
    "    xmajor = mdates.HourLocator(interval = 6)\n",
    "    xminor = mdates.HourLocator(interval = 1)\n",
    "    \n",
    "    print(ncss_times)\n",
    "    print(metar_data)\n",
    "    \n",
    "    \n",
    "\n",
    "    #\n",
    "    # Temperature and Humidity\n",
    "    #\n",
    "    \n",
    "    ax[0,0].plot(wrf_times,\n",
    "             (wrf_timeseries[\"air_temperature_2m\"]*units(\"K\")).pint.to(\"degF\"),\n",
    "              color = \"red\")\n",
    "    ax[0,0].plot(wrf_times,\n",
    "             (wrf_timeseries[\"dew_point_temperature_2m\"]*units(\"K\")).pint.to(\"degF\"),\n",
    "              color = \"blue\")\n",
    "    ax[0,0].set_ylabel(\"Temperature/DewPoint (°F)\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        ax[0,0].plot(ncss_times,\n",
    "                 (metar_data[\"air_temperature\"].to_numpy()*units(\"degC\")).to(\"degF\"),\n",
    "                 marker = \"o\",\n",
    "                 color=\"magenta\",\n",
    "                linestyle = \"None\")\n",
    "    except ValueError:\n",
    "        print(\"balls: air_temperature plot error\")\n",
    "\n",
    "    try:\n",
    "        ax[0,0].plot(ncss_times,\n",
    "                 (metar_data[\"dew_point_temperature\"].to_numpy()*units(\"degC\")).to(\"degF\"),\n",
    "                 marker = \"o\",\n",
    "                 color=\"cyan\",\n",
    "                linestyle = \"None\")\n",
    "    except ValueError:\n",
    "        print(\"balls: dew_point_temperature plot error\")\n",
    "\n",
    "\n",
    "    ax[0,1].set_title(\"Sta-to-WRF dist: \" + str(round(metar_to_wrf_distance,1)) +\" km\")\n",
    "    ax[0,0].set_title(\"Nearest Sta: \"     + weather_station_name +\" (\"+x.iloc[0]['station_id'] +\")\")\n",
    "        \n",
    "\n",
    "\n",
    "    #\n",
    "    # Total Atmos Column Water + Wind Speed\n",
    "    #\n",
    "    \n",
    "    ax[0,1].plot(wrf_times,\n",
    "            spd_wrf,\n",
    "              color = \"steelblue\")\n",
    "    ax[0,1].set_ylabel(\"WRF Wind Speed (kts)\")\n",
    " \n",
    "\n",
    "    ax01 = ax[0,1].twinx()\n",
    "    \n",
    "    ax01.set_ylim(0,1)\n",
    "    ax01.set_yticks([1/3.,2/3.])\n",
    "    ax01.set_yticklabels([\"WRF\",\"OBS\"])\n",
    "\n",
    "    \n",
    "    ax01.barbs( wrf_time_hrly, 1/3.,  u_wrf, v_wrf, color=Mines_Blue )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #try:\n",
    "    ax01.barbs( ncss_times,    \n",
    "                   2/3.,  \n",
    "                   u_obs.astype('float64'),                  \n",
    "                   v_obs.astype('float64'), \n",
    "                   color      = \"blue\")\n",
    "    #except:\n",
    "     #print(\"balls: wind plotting error\")\n",
    "\n",
    "   \n",
    "    \n",
    "    #\n",
    "    # Surface Energy Budget\n",
    "    #\n",
    "\n",
    "    ax[1,0].plot(wrf_times,\n",
    "                 wrf_timeseries[\"surface_net_downward_shortwave_flux\"],\n",
    "                 color = \"goldenrod\")\n",
    "    ax[1,0].plot(wrf_times,\n",
    "                 wrf_timeseries[\"surface_net_downward_longwave_flux\"],\n",
    "                 color = \"magenta\")\n",
    "    ax[1,0].plot(wrf_times,\n",
    "                 wrf_timeseries[\"surface_upward_sensible_heat_flux\"],\n",
    "                 color = \"red\")\n",
    "    ax[1,0].plot(wrf_times,\n",
    "                 wrf_timeseries[\"surface_upward_latent_heat_flux\"],\n",
    "                 color = \"blue\")\n",
    "    ax[1,0].legend([\"Solar↓\",\"LongWave↓\",\"Heat↑\",\"Evap↑\"],frameon=False)\n",
    "    ax[1,0].set_ylabel(\"Surface Energy Flux (W/m²)\")\n",
    "\n",
    "    ax[1,0].axhline(y=0,color=\"grey\", linewidth=0.5)\n",
    " \n",
    "    #\n",
    "    # Precipitation\n",
    "    #\n",
    "\n",
    "    ax[1,1].bar(wrf_time_hrly_bar,\n",
    "                wrf_hrly_prec,\n",
    "                linewidth=0,\n",
    "                width=1/24, \n",
    "                color=\"lightgreen\",\n",
    "                edgecolor=None)\n",
    "    ax11 = ax[1,1].twinx()\n",
    "    ax11.plot(wrf_times,\n",
    "              wrf_cum_prec, \n",
    "              color=\"darkgreen\")\n",
    "    ax11.set_ylabel(\"Cumulative Precipitation (in)\")\n",
    "    ax[1,1].set_ylabel(\"Hourly Precipitation (in)\")\n",
    "    ax[1,1].set_ylim(0., np.max([np.max(wrf_hrly_prec), 0.005]))\n",
    "    ax11.set_ylim(   0., np.max([np.max( wrf_cum_prec), 0.005]))\n",
    "    fig.suptitle(station_name+\"; Model Run \"+file_time+\"; WRF Domain \"+str(grid_domain),\n",
    "                 fontsize=20)\n",
    "\n",
    "\n",
    "    ax[1,0].set_xlim(model_start_datetime, model_end_datetime)\n",
    "    ax[1,0].xaxis.set_major_formatter(date_form)\n",
    "    ax[1,0].xaxis.set_major_locator(xmajor)\n",
    "    ax[1,0].xaxis.set_minor_locator(xminor)\n",
    "    ax[1,0].xaxis_date()\n",
    "\n",
    "    ax[1,1].set_xlim(model_start_datetime, model_end_datetime)\n",
    "    ax[1,1].xaxis.set_major_formatter(date_form)\n",
    "    ax[1,1].xaxis.set_major_locator(xmajor)\n",
    "    ax[1,1].xaxis.set_minor_locator(xminor)\n",
    "    ax[1,1].xaxis_date()\n",
    "\n",
    "    ax[0,0].set_xlim(model_start_datetime, model_end_datetime)\n",
    "    ax[0,0].xaxis.set_major_formatter(date_form)\n",
    "    ax[0,0].xaxis.set_major_locator(xmajor)\n",
    "    ax[0,0].xaxis.set_minor_locator(xminor)\n",
    "    ax[0,0].xaxis_date()\n",
    "\n",
    "    ax[0,1].set_xlim(model_start_datetime, model_end_datetime)\n",
    "    ax[0,1].xaxis.set_major_formatter(date_form)\n",
    "    ax[0,1].xaxis.set_major_locator(xmajor)\n",
    "    ax[0,1].xaxis.set_minor_locator(xminor)\n",
    "    ax[0,1].xaxis_date()\n",
    "\n",
    "    ax[0,0].spines[\"top\"].set_visible(False)\n",
    "    ax[1,0].spines[\"top\"].set_visible(False)\n",
    "    ax[0,1].spines[\"top\"].set_visible(False)\n",
    "    ax[1,1].spines[\"top\"].set_visible(False)\n",
    "    ax11.spines[   \"top\"].set_visible(False)\n",
    "    ax01.spines[   \"top\"].set_visible(False)\n",
    "\n",
    "    ax[0,0].spines[\"right\"].set_visible(False)\n",
    "    ax[1,0].spines[\"right\"].set_visible(False)\n",
    "    ax[0,1].spines[\"right\"].set_visible(False)\n",
    "    ax01.spines[   \"right\"].set_visible(False)\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "\n",
    "\n",
    "    # plt.show()\n",
    "    if (platform.system() != \"Darwin\"):\n",
    "        fig.savefig(graphics_directory + \"./wrfout_dxx_\"+file_time+\"_\"+station_id+\".png\",\n",
    "                        facecolor   = 'white', \n",
    "                        transparent =   False)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "    #\n",
    "    ###################################################################\n",
    "\n",
    "    #\n",
    "    ###################################################################\n",
    "    ###################################################################\n",
    "    \n",
    "    print(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e40ea1c-d483-4457-90dd-4117e945bf80",
   "metadata": {},
   "source": [
    "## Depart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# End of Script\n",
    "#\n",
    "\n",
    "print(\"Ploting Meteogram Script complete.\")\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1376f7b1-d228-469e-a314-e2741a535040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ee42c-c5a2-4f96-9e1c-fe874f0d5f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355305ec-cab7-49df-ae1c-e30f22396209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea11d70-119f-410f-8f2a-fceeeaabca6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdae9a-eb06-483c-8005-f22b0a5f94be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
