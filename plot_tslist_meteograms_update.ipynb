{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19dd65e-44a5-4f18-b94b-791b7765e094",
   "metadata": {},
   "source": [
    "# \n",
    "Plot Time Series w/ Observations (To get siphcat to get the text files -- USE THIS ONE!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f447c1-d96c-4e5f-a31e-e4c6fe161096",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9073fcc9-de66-43ad-b97e-b138bb803ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Libraries\n",
    "#\n",
    "\n",
    "import numpy             as np\n",
    "import datetime          as datetime\n",
    "import os                as os\n",
    "import platform          as platform\n",
    "import xarray            as xr\n",
    "import pandas            as pd\n",
    "import glob              as glob\n",
    "import siphon.catalog    as siphcat  \n",
    "import siphon.ncss       as siphncss\n",
    "import seaborn           as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pint_xarray       as px\n",
    "import pint              as pint\n",
    "import matplotlib.dates  as mdates\n",
    "import timezonefinder    as tzf\n",
    "import pytz              as pytz\n",
    "import haversine         as hs\n",
    "import socket            as socket\n",
    "import metpy.calc        as mpcalc\n",
    "import metpy.units       as mpunits\n",
    "import pathlib           as pathlib\n",
    "\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "import metpy.io          as mpio\n",
    "\n",
    "\n",
    "from requests import HTTPError\n",
    "\n",
    "\n",
    "from metpy.units import units\n",
    "\n",
    "import airportsdata as airpt\n",
    "\n",
    "ureg = pint.UnitRegistry()\n",
    "Q_ = ureg.Quantity\n",
    "\n",
    "\n",
    "def haversine(row):\n",
    "    lon1 = station_lon\n",
    "    lat1 = station_lat\n",
    "    lon2 = row['longitude']\n",
    "    lat2 = row['latitude']\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    km = 6367 * c\n",
    "    return km\n",
    "    \n",
    "    \n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29e546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Mines Colors and Fonts\n",
    "#\n",
    "\n",
    "Mines_Blue = \"#002554\"\n",
    "\n",
    "\n",
    "plt.rcParams.update({'text.color'      : Mines_Blue,\n",
    "                     'axes.labelcolor' : Mines_Blue,\n",
    "\t\t\t\t\t 'axes.edgecolor'  :Mines_Blue,\n",
    "\t\t\t\t\t 'xtick.color'     : Mines_Blue,\n",
    "\t\t\t\t\t 'ytick.color'    : Mines_Blue})\n",
    "\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54abbc2b-358d-4c0e-a1eb-0752574563f6",
   "metadata": {},
   "source": [
    "## File Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1513b9-a791-41cb-a4c6-67ba8ca945ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# File Organization\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "beta_on     = 0\n",
    "max_domains = 2\n",
    "\n",
    "if (socket.gethostname() == \"kyrill\"):\n",
    "    WRF_OVERALL_DIR = \"/projects/SD_Mines_WRF_REALTIME/\"\n",
    "else:\n",
    "    if (platform.system() == \"Darwin\"):\n",
    "         WRF_OVERALL_DIR = \"/Users/wjc/GitHub/SD_Mines_WRF_REALTIME/\"\n",
    "    else:\n",
    "         WRF_OVERALL_DIR = \"/home/wjc/GitHub/SD_Mines_WRF_REALTIME/\"\n",
    "\n",
    "\n",
    "os.chdir(WRF_OVERALL_DIR)\n",
    "\n",
    "print( \"Current Working Directory is now \" + os.getcwd() )\n",
    "    \n",
    "WPS_WORK    = WRF_OVERALL_DIR + \"./WPS_PrepArea/\"\n",
    "WPS_EXE     = WRF_OVERALL_DIR + \"./WRF4/WPS/\"\n",
    "WRF_EXE     = WRF_OVERALL_DIR + \"./WRF4/WRF/test/em_real/\"\n",
    "WRF_ARCHIVE = WRF_OVERALL_DIR + \"./ARCHIVE/\"\n",
    "WRF_IMAGES  = WRF_OVERALL_DIR + \"./WEB_IMAGES/\"\n",
    "METAR_DIR   = WRF_OVERALL_DIR + \"./METARS/\"\n",
    "\n",
    "\n",
    "\n",
    "station_list_file = WRF_OVERALL_DIR + \"namelist_files_and_local_scripts/time_series_station_files_\"+str(max_domains)+\"_dom_all.xlsx\"\n",
    "\n",
    "os.chdir(WRF_EXE)\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6054cd4-e5eb-47a1-b1b2-b92d7d7c723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Model Geographic Limits\n",
    "#\n",
    "\n",
    "f_geog = xr.open_dataset(filename_or_obj= WRF_ARCHIVE + \"/GEOGRID_EM_FILES/geo_em.d01.nc\")\n",
    "\n",
    "lat2d_d01 = f_geog[ \"XLAT_C\"]\n",
    "lon2d_d01 = f_geog[\"XLONG_C\"]\n",
    "\n",
    "geospatial_lat_min =  lat2d_d01.values.min()\n",
    "geospatial_lat_max =  lat2d_d01.values.max()\n",
    "geospatial_lon_min =  lon2d_d01.values.min()\n",
    "geospatial_lon_max =  lon2d_d01.values.max()\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916739ca-6473-4a28-a2c8-a37fd62271d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92a53e41-be5b-4d89-b19f-5fb97bc31de9",
   "metadata": {},
   "source": [
    "## Time Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d853823c-6405-4651-ae87-1c34da5c3db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(WRF_ARCHIVE  + \"./current_complete_run/current_run.txt\") as f:\n",
    "    model_start_date_YYYY_MM_DD_HH = f.readlines()\n",
    "\n",
    "model_start_date_YYYY_MM_DD_HH     = model_start_date_YYYY_MM_DD_HH[0][0:13]\n",
    "\n",
    "model_start_date_YYYY_MM_DD_HH0000 = model_start_date_YYYY_MM_DD_HH + \":00:00\"\n",
    "print(model_start_date_YYYY_MM_DD_HH0000)\n",
    "    \n",
    "model_start_datetime = datetime.datetime.strptime(model_start_date_YYYY_MM_DD_HH0000, '%Y-%m-%d_%H:%M:%S')\n",
    "print(\"Model Simulation Date \", model_start_datetime)\n",
    "    \n",
    "model_end_datetime   = model_start_datetime + datetime.timedelta(hours=36)\n",
    "current_datetime     = datetime.datetime.utcnow()\n",
    "siphon_end_datetime  = min(current_datetime,model_end_datetime)\n",
    "\n",
    "print(\"         Model Start Datetime is \", model_start_datetime)\n",
    "print(\"           Model End Datetime is \",   model_end_datetime)\n",
    "print(\"             Current Datetime is \",     current_datetime)\n",
    "print(\"          Siphon End Datetime is \",  siphon_end_datetime)\n",
    "\n",
    "\n",
    "siphon_time_series       = pd.date_range(model_start_datetime, siphon_end_datetime,freq='h')\n",
    "siphon_pulls_YYYYMMDD_HH = siphon_time_series.strftime(\"%Y%m%d_%H00\")\n",
    "\n",
    "print(siphon_pulls_YYYYMMDD_HH)\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128f1f13-21b4-4ee1-ae4c-7e551914c5a1",
   "metadata": {},
   "source": [
    "## Read tslist excel file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d9f40-9106-41b1-b8a7-727e33172e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Read TSLIST Excel File\n",
    "#\n",
    "\n",
    "print(\"read file from \"+station_list_file)\n",
    "\n",
    "available_time_series_list = pd.read_excel(station_list_file,\n",
    "                                           index_col=0)\n",
    "\n",
    "print(available_time_series_list)\n",
    "\n",
    "target_time_series_as_list = available_time_series_list[\"Station ID\"].to_list()\n",
    "print(target_time_series_as_list)\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1fc178",
   "metadata": {},
   "source": [
    "## Get Station Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0274cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Airport Data\n",
    "#\n",
    "\n",
    "airport_database = airpt.load('ICAO')\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62308d5",
   "metadata": {},
   "source": [
    "## Pull METARS from Siphon Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec290040",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Pull METARS from UNIDATA NOAAPORT Experimental Site\n",
    "#\n",
    "# https://thredds-test.unidata.ucar.edu/thredds/fileServer/noaaport/text/metar/metar_20210924_0000.txt\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "print(\"Box = \",geospatial_lat_min, geospatial_lat_max)\n",
    "print(\"      \",geospatial_lon_min, geospatial_lon_max)\n",
    "\n",
    "\n",
    "first = True\n",
    "for datehour in siphon_pulls_YYYYMMDD_HH:\n",
    "\n",
    "    # URLs & Local Work File Names\n",
    "    \n",
    "    metar_url  = \"https://thredds-dev.unidata.ucar.edu/thredds/fileServer/noaaport/text/metar/metar_\"+datehour+\".txt\"\n",
    "    metar_file = METAR_DIR + \"./metar_\"+datehour+\".txt\"\n",
    "    \n",
    "    path_to_file = pathlib.Path(metar_file)\n",
    "    \n",
    "    print(path_to_file, path_to_file.is_file())\n",
    "\n",
    "    # Pull File \n",
    "    \n",
    "    print(\"downloading \"+ metar_url)\n",
    "    with urllib.request.urlopen(metar_url) as response, open(metar_file, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)\n",
    "            \n",
    "    print(\"cracking \"+metar_file)\n",
    "    try:\n",
    "        indata = mpio.metar.parse_metar_file(metar_file)\n",
    "        indata = indata[(indata['latitude']  > geospatial_lat_min) & \n",
    "                        (indata['latitude']  < geospatial_lat_max) &\n",
    "                        (indata['longitude'] > geospatial_lon_min) &\n",
    "                        (indata['longitude'] < geospatial_lon_max) ]\n",
    "        indata = indata.drop([\"current_wx2_symbol\",\n",
    "                              \"current_wx3_symbol\",\n",
    "                              \"current_wx1\",\n",
    "                              \"current_wx2\",\n",
    "                              \"current_wx3\",\n",
    "                              \"altimeter\",\n",
    "                              \"wind_gust\",\n",
    "                              \"visibility\",\n",
    "                              \"cloud_coverage\",\n",
    "                              \"current_wx1_symbol\",\n",
    "                              \"air_pressure_at_sea_level\",\n",
    "                              \"remarks\",\n",
    "                              \"low_cloud_type\", \n",
    "                              \"low_cloud_level\", \n",
    "                              \"medium_cloud_type\",\n",
    "                              \"medium_cloud_level\", \n",
    "                              \"high_cloud_type\", \n",
    "                              \"high_cloud_level\",\n",
    "                              \"highest_cloud_type\", \n",
    "                              \"highest_cloud_level\"], axis=1)\n",
    "        if first:\n",
    "            first = False\n",
    "            metar_dataframe = indata\n",
    "        else:\n",
    "            metar_dataframe = pd.concat(objs = [metar_dataframe,indata],\n",
    "                                        axis =                  \"index\")\n",
    "    except ValueError:\n",
    "        print(\"BALLS! Parse Error\")\n",
    "        error_404 = True\n",
    "        pass\n",
    "\n",
    "# Cookiecut the Radar Domain Metars and Clean Data Table\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metar_dataframe = metar_dataframe.sort_values(\"date_time\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(    \"purging \" + METAR_DIR + \"./metar_*.txt\")\n",
    "os.system(\"rm -frv \" + METAR_DIR + \"./metar_*.txt\")\n",
    "\n",
    "print(\"Dropping Duplicate Records\")\n",
    "\n",
    "metar_dataframe = metar_dataframe.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    metar_station_locs = metar_dataframe[[\"station_id\",\"latitude\",\"longitude\"]].drop_duplicates()\n",
    "except:\n",
    "    print(\"Dangit: there is no metar stations to locate\")\n",
    "\n",
    "print(\"Storing Data in CSVs\")\n",
    "metar_station_locs.to_csv(WRF_OVERALL_DIR + \"Metar_loc_dump.csv\")\n",
    "metar_dataframe.to_csv(   WRF_OVERALL_DIR + \"Metar_Dump.csv\")\n",
    "print(\"Metar Extraction Complete\")\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a899ce-0e6d-472c-bd3a-d40ecf3302bb",
   "metadata": {},
   "source": [
    "## Rotate through Available Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93f7c6-99d0-4e48-a615-84c5b3ab9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_wrf, v_wrf, u_wrf.coords[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b13c37-b597-4d0c-bb60-ab054c9b70f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncss_times.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647bb3fa-f35e-4c77-90c8-53253f5499a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# Rotate through Available Files\n",
    "#\n",
    "\n",
    "file_time = model_start_datetime.strftime('%Y-%m-%d_%H')\n",
    "\n",
    "TS_DIR    = WRF_ARCHIVE  + \"./current_complete_run/STATION_TIME_SERIES/\"\n",
    "\n",
    "#\n",
    "# Creating Graphics Directory\n",
    "#\n",
    "\n",
    "graphics_directory = WRF_IMAGES + \"./current_complete_run/STATION_TIME_SERIES/\"\n",
    "\n",
    "print(\"Creating \" + graphics_directory)\n",
    "\n",
    "os.system(\"mkdir -pv \" + graphics_directory )\n",
    "\n",
    "#\n",
    "# Start File Rotation\n",
    "#\n",
    "\n",
    "\n",
    "for station_row in range(len(available_time_series_list)):\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Pull Station Data \n",
    "    #\n",
    "\n",
    "\n",
    "\n",
    "    station_id     = available_time_series_list.iloc[station_row][\"Station ID\"]\n",
    "    grid_domain    = available_time_series_list.iloc[station_row][\"Domain\"]\n",
    "    station_name   = available_time_series_list.iloc[station_row][\"Station Name\"]\n",
    "    station_lat    = available_time_series_list.iloc[station_row][\"Latitude\"]\n",
    "    station_lon    = available_time_series_list.iloc[station_row][\"Longitude\"]\n",
    "\n",
    "\n",
    "    #    \n",
    "    ###################################################################\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Pull WRF Time Series\n",
    "    #\n",
    "    \n",
    "    netcdf_file_name = TS_DIR + \"./wrfout_d\"+str(grid_domain).zfill(2)+\"_\"+file_time+\"_\"+station_id+\".nc\"\n",
    "    \n",
    "    wrf_timeseries = xr.open_dataset(netcdf_file_name, \n",
    "                                     engine='netcdf4')\n",
    "    \n",
    "    print(netcdf_file_name)\n",
    "\n",
    "    #\n",
    "    ###################################################################\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Select Metars for Closest Station\n",
    "    #\n",
    "\n",
    "  \n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Get METARS for Station \n",
    "    #\n",
    "    \n",
    "\n",
    "\n",
    "    #\n",
    "    # Get Nearest Station to Requested Station Point\n",
    "    #\n",
    "    \n",
    "    metar_station_locs['distance'] = metar_station_locs.apply(lambda row: haversine(row), axis=1)\n",
    "    \n",
    "    x=metar_station_locs[ metar_station_locs['distance'] == metar_station_locs['distance'].min() ]\n",
    "    \n",
    "    try:\n",
    "        weather_station_name = airport_database[x.iloc[0]['station_id']][\"name\"] #+\", \"+airport_database[x['station_id'][0]][\"subd\"]\n",
    "        print(\"Weatherstation from airport database \", weather_station_name)\n",
    "    except KeyError:\n",
    "        weather_station_name = x.iloc[0]['station_id']\n",
    "        print(\"Weatherstation from short table \", weather_station_name)\n",
    "\n",
    "               \n",
    "    metar_data = metar_dataframe[metar_dataframe[\"station_id\"]==x.iloc[0]['station_id']].set_index(\"date_time\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"lon metar/station/wrf:\",metar_data.iloc[0][\"longitude\"],station_lon,wrf_timeseries[\"wrf_grid_longitude\"].values)\n",
    "    print(\"lat metar/station/wrf:\",metar_data.iloc[0][ \"latitude\"],station_lat,wrf_timeseries[\"wrf_grid_latitude\"].values)\n",
    "\n",
    "   \n",
    "\n",
    "    metar_to_sta_distance  = hs.haversine((metar_data.iloc[0][ \"latitude\"],\n",
    "                                           metar_data.iloc[0][\"longitude\"]),\n",
    "                                          (station_lat,\n",
    "                                           station_lon))\n",
    "\n",
    "    metar_to_wrf_distance = hs.haversine((metar_data.iloc[0][ \"latitude\"],\n",
    "                                          metar_data.iloc[0][\"longitude\"]),\n",
    "                                          (wrf_timeseries[\"wrf_grid_latitude\" ].values[0],\n",
    "                                           wrf_timeseries[\"wrf_grid_longitude\"].values[0]))\n",
    "\n",
    "\n",
    "    sta_to_wrf_distance   = hs.haversine((station_lat,\n",
    "                                          station_lon),\n",
    "                                         (wrf_timeseries[\"wrf_grid_latitude\" ].values[0],\n",
    "                                          wrf_timeseries[\"wrf_grid_longitude\"].values[0]))    \n",
    "    \n",
    "    print(\"distance between  metar and tslist \",metar_to_sta_distance)\n",
    "    print(\"distance between  metar and    wrf \",metar_to_wrf_distance)\n",
    "    print(\"distance between tslist and    wrf \",sta_to_wrf_distance)\n",
    "\n",
    "    \n",
    "    \n",
    "    #    \n",
    "    ###################################################################    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #\n",
    "    ###################################################################    \n",
    "    \n",
    "\n",
    "    ###################################################################\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Create Meteogram\n",
    "    #\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Time Axes\n",
    "    #\n",
    "                                         \n",
    "    tf     = tzf.TimezoneFinder()\n",
    "    tz     = tf.certain_timezone_at(lng=station_lon, lat=station_lat)\n",
    "    \n",
    "    tzabbr = pytz.timezone(tz).localize(model_start_datetime)\n",
    "\n",
    "    wrf_times  = pd.to_datetime(wrf_timeseries[\"time\"]).tz_localize(tz=\"UTC\").tz_convert(tz=tz)\n",
    "    \n",
    "    ncss_times = pd.to_datetime(metar_data.index).tz_localize(tz=\"UTC\").tz_convert(tz=tz)\n",
    "\n",
    "\n",
    "\n",
    "    wrf_time_seconds  =  wrf_times.minute*60+wrf_times.second \n",
    "    on_the_hour       = np.where(wrf_time_seconds ==0)\n",
    "    wrf_time_hrly     = wrf_times[on_the_hour]\n",
    "    wrf_time_hrly_bar = wrf_times[on_the_hour]-datetime.timedelta(minutes=30)\n",
    "\n",
    "    #\n",
    "    ###################################################################\n",
    "\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Precip Prep\n",
    "    #\n",
    "\n",
    "    wrf_cum_prec      = wrf_timeseries[\"stratiform_precipitation_amount\"].values + wrf_timeseries[\"convective_precipitation_amount\"].values\n",
    "    print(\"Total precip: \",np.sum(wrf_cum_prec)/25.4, \" in\")\n",
    "    if (np.sum(wrf_cum_prec)/25.4 < 0.005):\n",
    "        print(\"No Significant Rainfall\")\n",
    "        wrf_cum_prec[:] = 0.000\n",
    "    \n",
    "    wrf_cum_hrly_prec = wrf_cum_prec[on_the_hour]\n",
    "    wrf_hrly_prec     = wrf_cum_hrly_prec.copy()\n",
    "\n",
    "    wrf_hrly_prec[1:] = wrf_cum_hrly_prec[1:] - wrf_cum_hrly_prec[0:-1]\n",
    "    \n",
    "    wrf_hrly_prec     = wrf_hrly_prec     / 25.4\n",
    "    wrf_cum_hrly_prec = wrf_cum_hrly_prec / 25.4\n",
    "    wrf_cum_prec      = wrf_cum_prec      / 25.4\n",
    "\n",
    "    #\n",
    "    ###################################################################\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Wind Barb Prep\n",
    "    #\n",
    "\n",
    "    u_wrf = (wrf_timeseries[\"eastward_wind_10m\"]*units(\"m\")/units(\"s\")).pint.to(\"knots\")[on_the_hour]\n",
    "    v_wrf = (wrf_timeseries[\"northward_wind_10m\"]*units(\"m\")/units(\"s\")).pint.to(\"knots\")[on_the_hour]\n",
    "\n",
    "    spd_wrf = np.sqrt(wrf_timeseries[ \"eastward_wind_10m\"]**2 + \n",
    "                      wrf_timeseries[\"northward_wind_10m\"]**2 )\n",
    "    \n",
    "    \n",
    "    spd_wrf = (spd_wrf *units(\"m\")/units(\"s\")).pint.to(\"knots\")                 \n",
    "\n",
    "    obs_winddir   =  metar_data[\"wind_direction\"].to_numpy() * units(\"deg\")\n",
    "    obs_windspeed = (metar_data[\"wind_speed\"].to_numpy() * units(\"m\")/units(\"s\")).to(\"knots\") \n",
    "\n",
    "\n",
    "\n",
    "    u_obs = (metar_data[ \"eastward_wind\"].to_numpy() * units(\"m\")/units(\"s\")).to(\"knots\") \n",
    "    v_obs = (metar_data[\"northward_wind\"].to_numpy() * units(\"m\")/units(\"s\")).to(\"knots\") \n",
    "\n",
    "    #u_obs = xr.DataArray(data=u_obs)#, coords={\"time\":ncss_times})\n",
    "    #v_obs = xr.DataArray(data=v_obs)#, coords={\"time\":ncss_times})\n",
    "    #\n",
    "    ###################################################################\n",
    "\n",
    "    ###################################################################\n",
    "    #\n",
    "    # Plot Meteogram\n",
    "    #\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12, 8),\n",
    "                           nrows   =  2, \n",
    "                           ncols   =  2,\n",
    "                           sharex  =  True)\n",
    "\n",
    "    date_form = mdates.DateFormatter(\"%H %Z\\n%d %b\", tz=pytz.timezone(tz))\n",
    "    xmajor = mdates.HourLocator(interval = 6)\n",
    "    xminor = mdates.HourLocator(interval = 1)\n",
    "    \n",
    "    print(ncss_times)\n",
    "    print(metar_data)\n",
    "    \n",
    "    \n",
    "\n",
    "    #\n",
    "    # Temperature and Humidity\n",
    "    #\n",
    "    \n",
    "    ax[0,0].plot(wrf_times,\n",
    "             (wrf_timeseries[\"air_temperature_2m\"]*units(\"K\")).pint.to(\"degF\"),\n",
    "              color = \"red\")\n",
    "    ax[0,0].plot(wrf_times,\n",
    "             (wrf_timeseries[\"dew_point_temperature_2m\"]*units(\"K\")).pint.to(\"degF\"),\n",
    "              color = \"blue\")\n",
    "    ax[0,0].set_ylabel(\"Temperature/DewPoint (°F)\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        ax[0,0].plot(ncss_times,\n",
    "                 (metar_data[\"air_temperature\"].to_numpy()*units(\"degC\")).to(\"degF\"),\n",
    "                 marker = \"o\",\n",
    "                 color=\"magenta\",\n",
    "                linestyle = \"None\")\n",
    "    except ValueError:\n",
    "        print(\"balls: air_temperature plot error\")\n",
    "\n",
    "    try:\n",
    "        ax[0,0].plot(ncss_times,\n",
    "                 (metar_data[\"dew_point_temperature\"].to_numpy()*units(\"degC\")).to(\"degF\"),\n",
    "                 marker = \"o\",\n",
    "                 color=\"cyan\",\n",
    "                linestyle = \"None\")\n",
    "    except ValueError:\n",
    "        print(\"balls: dew_point_temperature plot error\")\n",
    "\n",
    "\n",
    "    ax[0,1].set_title(\"Sta-to-WRF dist: \" + str(round(metar_to_wrf_distance,1)) +\" km\")\n",
    "    ax[0,0].set_title(\"Nearest Sta: \"     + weather_station_name +\" (\"+x.iloc[0]['station_id'] +\")\")\n",
    "        \n",
    "\n",
    "\n",
    "    #\n",
    "    # Total Atmos Column Water + Wind Speed\n",
    "    #\n",
    "    \n",
    "    ax[0,1].plot(wrf_times,\n",
    "            spd_wrf,\n",
    "              color = \"steelblue\")\n",
    "    ax[0,1].set_ylabel(\"WRF Wind Speed (kts)\")\n",
    " \n",
    "\n",
    "    ax01 = ax[0,1].twinx()\n",
    "    \n",
    "    ax01.set_ylim(0,1)\n",
    "    ax01.set_yticks([1/3.,2/3.])\n",
    "    ax01.set_yticklabels([\"WRF\",\"OBS\"])\n",
    "\n",
    "    \n",
    "    ax01.barbs( wrf_time_hrly, 1/3.,  u_wrf, v_wrf, color=Mines_Blue )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    #try:\n",
    "    ax01.barbs( ncss_times,    \n",
    "                   2/3.,  \n",
    "                   u_obs.astype('float64'),                  \n",
    "                   v_obs.astype('float64'), \n",
    "                   color      = \"blue\")\n",
    "    #except:\n",
    "     #print(\"balls: wind plotting error\")\n",
    "\n",
    "   \n",
    "    \n",
    "    #\n",
    "    # Surface Energy Budget\n",
    "    #\n",
    "\n",
    "    ax[1,0].plot(wrf_times,\n",
    "                 wrf_timeseries[\"surface_net_downward_shortwave_flux\"],\n",
    "                 color = \"goldenrod\")\n",
    "    ax[1,0].plot(wrf_times,\n",
    "                 wrf_timeseries[\"surface_net_downward_longwave_flux\"],\n",
    "                 color = \"magenta\")\n",
    "    ax[1,0].plot(wrf_times,\n",
    "                 wrf_timeseries[\"surface_upward_sensible_heat_flux\"],\n",
    "                 color = \"red\")\n",
    "    ax[1,0].plot(wrf_times,\n",
    "                 wrf_timeseries[\"surface_upward_latent_heat_flux\"],\n",
    "                 color = \"blue\")\n",
    "    ax[1,0].legend([\"Solar↓\",\"LongWave↓\",\"Heat↑\",\"Evap↑\"],frameon=False)\n",
    "    ax[1,0].set_ylabel(\"Surface Energy Flux (W/m²)\")\n",
    "\n",
    "    ax[1,0].axhline(y=0,color=\"grey\", linewidth=0.5)\n",
    " \n",
    "    #\n",
    "    # Precipitation\n",
    "    #\n",
    "\n",
    "    ax[1,1].bar(wrf_time_hrly_bar,\n",
    "                wrf_hrly_prec,\n",
    "                linewidth=0,\n",
    "                width=1/24, \n",
    "                color=\"lightgreen\",\n",
    "                edgecolor=None)\n",
    "    ax11 = ax[1,1].twinx()\n",
    "    ax11.plot(wrf_times,\n",
    "              wrf_cum_prec, \n",
    "              color=\"darkgreen\")\n",
    "    ax11.set_ylabel(\"Cumulative Precipitation (in)\")\n",
    "    ax[1,1].set_ylabel(\"Hourly Precipitation (in)\")\n",
    "    ax[1,1].set_ylim(0., np.max([np.max(wrf_hrly_prec), 0.005]))\n",
    "    ax11.set_ylim(   0., np.max([np.max( wrf_cum_prec), 0.005]))\n",
    "    fig.suptitle(station_name+\"; Model Run \"+file_time+\"; WRF Domain \"+str(grid_domain),\n",
    "                 fontsize=20)\n",
    "\n",
    "\n",
    "    ax[1,0].set_xlim(model_start_datetime, model_end_datetime)\n",
    "    ax[1,0].xaxis.set_major_formatter(date_form)\n",
    "    ax[1,0].xaxis.set_major_locator(xmajor)\n",
    "    ax[1,0].xaxis.set_minor_locator(xminor)\n",
    "    ax[1,0].xaxis_date()\n",
    "\n",
    "    ax[1,1].set_xlim(model_start_datetime, model_end_datetime)\n",
    "    ax[1,1].xaxis.set_major_formatter(date_form)\n",
    "    ax[1,1].xaxis.set_major_locator(xmajor)\n",
    "    ax[1,1].xaxis.set_minor_locator(xminor)\n",
    "    ax[1,1].xaxis_date()\n",
    "\n",
    "    ax[0,0].set_xlim(model_start_datetime, model_end_datetime)\n",
    "    ax[0,0].xaxis.set_major_formatter(date_form)\n",
    "    ax[0,0].xaxis.set_major_locator(xmajor)\n",
    "    ax[0,0].xaxis.set_minor_locator(xminor)\n",
    "    ax[0,0].xaxis_date()\n",
    "\n",
    "    ax[0,1].set_xlim(model_start_datetime, model_end_datetime)\n",
    "    ax[0,1].xaxis.set_major_formatter(date_form)\n",
    "    ax[0,1].xaxis.set_major_locator(xmajor)\n",
    "    ax[0,1].xaxis.set_minor_locator(xminor)\n",
    "    ax[0,1].xaxis_date()\n",
    "\n",
    "    ax[0,0].spines[\"top\"].set_visible(False)\n",
    "    ax[1,0].spines[\"top\"].set_visible(False)\n",
    "    ax[0,1].spines[\"top\"].set_visible(False)\n",
    "    ax[1,1].spines[\"top\"].set_visible(False)\n",
    "    ax11.spines[   \"top\"].set_visible(False)\n",
    "    ax01.spines[   \"top\"].set_visible(False)\n",
    "\n",
    "    ax[0,0].spines[\"right\"].set_visible(False)\n",
    "    ax[1,0].spines[\"right\"].set_visible(False)\n",
    "    ax[0,1].spines[\"right\"].set_visible(False)\n",
    "    ax01.spines[   \"right\"].set_visible(False)\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "\n",
    "\n",
    "    # plt.show()\n",
    "    if (platform.system() != \"Darwin\"):\n",
    "        fig.savefig(graphics_directory + \"./wrfout_dxx_\"+file_time+\"_\"+station_id+\".png\",\n",
    "                        facecolor   = 'white', \n",
    "                        transparent =   False)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "    plt.close('all')\n",
    "\n",
    "\n",
    "    #\n",
    "    ###################################################################\n",
    "\n",
    "    #\n",
    "    ###################################################################\n",
    "    ###################################################################\n",
    "    \n",
    "    print(\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e40ea1c-d483-4457-90dd-4117e945bf80",
   "metadata": {},
   "source": [
    "## Depart "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "#\n",
    "# End of Script\n",
    "#\n",
    "\n",
    "print(\"Ploting Meteogram Script complete.\")\n",
    "\n",
    "#\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1376f7b1-d228-469e-a314-e2741a535040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ee42c-c5a2-4f96-9e1c-fe874f0d5f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355305ec-cab7-49df-ae1c-e30f22396209",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(spd_wrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea11d70-119f-410f-8f2a-fceeeaabca6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdae9a-eb06-483c-8005-f22b0a5f94be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
